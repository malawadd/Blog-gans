{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'horses'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist, cifar100,cifar10\n",
    "\n",
    "def load_cifar(label, num):\n",
    "    if num == 10:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    else:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode = 'fine')\n",
    "\n",
    "    train_mask = [y[0]==label for y in y_train]\n",
    "    test_mask = [y[0]==label for y in y_test]\n",
    "\n",
    "    x_data = np.concatenate([x_train[train_mask], x_test[test_mask]])\n",
    "    y_data = np.concatenate([y_train[train_mask], y_test[test_mask]])\n",
    "\n",
    "    x_data = (x_data.astype('float32') - 127.5) / 127.5\n",
    " \n",
    "    return (x_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NAME == 'cars':\n",
    "    label = 1\n",
    "elif DATA_NAME == 'horses':\n",
    "    label = 7\n",
    "(x_train, y_train) = load_cifar(label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1939ca48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x_train[150,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , critic_conv_filters\n",
    "        , critic_conv_kernel_size\n",
    "        , critic_conv_strides\n",
    "        , critic_batch_norm_momentum\n",
    "        , critic_activation\n",
    "        , critic_dropout_rate\n",
    "        , critic_learning_rate\n",
    "        , generator_initial_dense_layer_size\n",
    "        , generator_upsample\n",
    "        , generator_conv_filters\n",
    "        , generator_conv_kernel_size\n",
    "        , generator_conv_strides\n",
    "        , generator_batch_norm_momentum\n",
    "        , generator_activation\n",
    "        , generator_dropout_rate\n",
    "        , generator_learning_rate\n",
    "        , optimiser\n",
    "        , z_dim\n",
    "        ):\n",
    "\n",
    "        self.name = 'gan'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.critic_conv_filters = critic_conv_filters\n",
    "        self.critic_conv_kernel_size = critic_conv_kernel_size\n",
    "        self.critic_conv_strides = critic_conv_strides\n",
    "        self.critic_batch_norm_momentum = critic_batch_norm_momentum\n",
    "        self.critic_activation = critic_activation\n",
    "        self.critic_dropout_rate = critic_dropout_rate\n",
    "        self.critic_learning_rate = critic_learning_rate\n",
    "\n",
    "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
    "        self.generator_upsample = generator_upsample\n",
    "        self.generator_conv_filters = generator_conv_filters\n",
    "        self.generator_conv_kernel_size = generator_conv_kernel_size\n",
    "        self.generator_conv_strides = generator_conv_strides\n",
    "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
    "        self.generator_activation = generator_activation\n",
    "        self.generator_dropout_rate = generator_dropout_rate\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        \n",
    "        self.optimiser = optimiser\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        \n",
    "\n",
    "        self.n_layers_critic = len(critic_conv_filters)\n",
    "        self.n_layers_generator = len(generator_conv_filters)\n",
    "\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    \n",
    "        self._build_critic()\n",
    "        self._build_generator()\n",
    "\n",
    "        self._build_adversarial()\n",
    "\n",
    "    def wasserstein(self, y_true, y_pred):\n",
    "        return - K.mean(y_true * y_pred)\n",
    "\n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'leaky_relu':\n",
    "            layer = LeakyReLU(alpha = 0.2)\n",
    "        else:\n",
    "            layer = Activation(activation)\n",
    "        return layer\n",
    "\n",
    "    def _build_critic(self):\n",
    "\n",
    "        ### THE critic\n",
    "        critic_input = Input(shape=self.input_dim, name='critic_input')\n",
    "\n",
    "        x = critic_input\n",
    "\n",
    "        for i in range(self.n_layers_critic):\n",
    "\n",
    "            x = Conv2D(\n",
    "                filters = self.critic_conv_filters[i]\n",
    "                , kernel_size = self.critic_conv_kernel_size[i]\n",
    "                , strides = self.critic_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'critic_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "\n",
    "            if self.critic_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum = self.critic_batch_norm_momentum)(x)\n",
    "\n",
    "            x = self.get_activation(self.critic_activation)(x)\n",
    "\n",
    "            if self.critic_dropout_rate:\n",
    "                x = Dropout(rate = self.critic_dropout_rate)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        # x = Dense(512, kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        # x = self.get_activation(self.critic_activation)(x)\n",
    "        \n",
    "        critic_output = Dense(1, activation=None\n",
    "        , kernel_initializer = self.weight_init\n",
    "        )(x)\n",
    "\n",
    "        self.critic = Model(critic_input, critic_output)\n",
    "\n",
    "\n",
    "\n",
    "    def _build_generator(self):\n",
    "\n",
    "        ### THE generator\n",
    "\n",
    "        generator_input = Input(shape=(self.z_dim,), name='generator_input')\n",
    "\n",
    "        x = generator_input\n",
    "\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size)\n",
    "        ,kernel_initializer = self.weight_init\n",
    "        )(x)\n",
    "\n",
    "        \n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "        x = self.get_activation(self.generator_activation)(x)\n",
    "\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate = self.generator_dropout_rate)(x)\n",
    "\n",
    "        for i in range(self.n_layers_generator):\n",
    "\n",
    "            if self.generator_upsample[i] == 2:\n",
    "                x = UpSampling2D()(x)\n",
    "                x = Conv2D(\n",
    "                filters = self.generator_conv_filters[i]\n",
    "                , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'generator_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "            else:\n",
    "\n",
    "                x = Conv2DTranspose(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , strides = self.generator_conv_strides[i]\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                    )(x)\n",
    "\n",
    "            if i < self.n_layers_generator - 1:\n",
    "\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "                x = self.get_activation(self.generator_activation)(x)\n",
    "            \n",
    "            else:\n",
    "                x = Activation('tanh')(x)\n",
    "\n",
    "\n",
    "        generator_output = x\n",
    "\n",
    "        self.generator = Model(generator_input, generator_output)\n",
    "\n",
    "\n",
    "    def get_opti(self, lr):\n",
    "        if self.optimiser == 'adam':\n",
    "            opti = Adam(lr=lr, beta_1=0.5)\n",
    "        elif self.optimiser == 'rmsprop':\n",
    "            opti = RMSprop(lr=lr)\n",
    "        else:\n",
    "            opti = Adam(lr=lr)\n",
    "\n",
    "        return opti\n",
    "\n",
    "    def set_trainable(self, m, val):\n",
    "        m.trainable = val\n",
    "        for l in m.layers:\n",
    "            l.trainable = val\n",
    "\n",
    "\n",
    "    def _build_adversarial(self):\n",
    "        \n",
    "        ### COMPILE critic\n",
    "\n",
    "        self.critic.compile(\n",
    "            optimizer=self.get_opti(self.critic_learning_rate) \n",
    "            , loss = self.wasserstein\n",
    "        )\n",
    "        \n",
    "        ### COMPILE THE FULL GAN\n",
    "\n",
    "        self.set_trainable(self.critic, False)\n",
    "\n",
    "        model_input = Input(shape=(self.z_dim,), name='model_input')\n",
    "        model_output = self.critic(self.generator(model_input))\n",
    "        self.model = Model(model_input, model_output)\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=self.get_opti(self.generator_learning_rate)\n",
    "            , loss=self.wasserstein\n",
    "            )\n",
    "\n",
    "        self.set_trainable(self.critic, True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train_critic(self, x_train, batch_size, clip_threshold, using_generator):\n",
    "\n",
    "        valid = np.ones((batch_size,1))\n",
    "        fake = -np.ones((batch_size,1))\n",
    "\n",
    "        if using_generator:\n",
    "            true_imgs = next(x_train)[0]\n",
    "            if true_imgs.shape[0] != batch_size:\n",
    "                true_imgs = next(x_train)[0]\n",
    "        else:\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            true_imgs = x_train[idx]\n",
    "        \n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        d_loss_real =   self.critic.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake =   self.critic.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "        for l in self.critic.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -clip_threshold, clip_threshold) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # for l in self.critic.layers:\n",
    "        \n",
    "        #     weights = l.get_weights()\n",
    "        #     if 'batch_normalization' in l.get_config()['name']:\n",
    "        #         pass\n",
    "        #         # weights = [np.clip(w, -0.01, 0.01) for w in weights[:2]] + weights[2:]\n",
    "        #     else:\n",
    "        #         weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            \n",
    "        #     l.set_weights(weights)\n",
    "\n",
    "        return [d_loss, d_loss_real, d_loss_fake]\n",
    "\n",
    "    def train_generator(self, batch_size):\n",
    "        valid = np.ones((batch_size,1))\n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        return self.model.train_on_batch(noise, valid)\n",
    "\n",
    "\n",
    "    def train(self, x_train, batch_size, epochs, run_folder, print_every_n_batches = 10\n",
    "        , n_critic = 5\n",
    "        , clip_threshold = 0.01\n",
    "        , using_generator = False):\n",
    "\n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "\n",
    "            for _ in range(n_critic):\n",
    "                d_loss = self.train_critic(x_train, batch_size, clip_threshold, using_generator)\n",
    "\n",
    "            g_loss = self.train_generator(batch_size)\n",
    "               \n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)]  [G loss: %.3f] \" % (epoch, d_loss[0], d_loss[1], d_loss[2], g_loss))\n",
    "            \n",
    "            self.d_losses.append(d_loss)\n",
    "            self.g_losses.append(g_loss)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % print_every_n_batches == 0:\n",
    "                self.sample_images(run_folder)\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
    "                self.save_model(run_folder)\n",
    "            \n",
    "            self.epoch+=1\n",
    "\n",
    "    def sample_images(self, run_folder):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        #Rescale images 0 - 1\n",
    "\n",
    "        gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(run_folder, \"images/sample_%d.png\" % self.epoch))\n",
    "        plt.close()\n",
    "\n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.critic, to_file=os.path.join(run_folder ,'viz/critic.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.generator, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes = True, show_layer_names = True)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    def save(self, folder):\n",
    "\n",
    "            with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
    "                pickle.dump([\n",
    "                    self.input_dim\n",
    "                    , self.critic_conv_filters\n",
    "                    , self.critic_conv_kernel_size\n",
    "                    , self.critic_conv_strides\n",
    "                    , self.critic_batch_norm_momentum\n",
    "                    , self.critic_activation\n",
    "                    , self.critic_dropout_rate\n",
    "                    , self.critic_learning_rate\n",
    "                    , self.generator_initial_dense_layer_size\n",
    "                    , self.generator_upsample\n",
    "                    , self.generator_conv_filters\n",
    "                    , self.generator_conv_kernel_size\n",
    "                    , self.generator_conv_strides\n",
    "                    , self.generator_batch_norm_momentum\n",
    "                    , self.generator_activation\n",
    "                    , self.generator_dropout_rate\n",
    "                    , self.generator_learning_rate\n",
    "                    , self.optimiser\n",
    "                    , self.z_dim\n",
    "                    ], f)\n",
    "\n",
    "            self.plot_model(folder)\n",
    "\n",
    "    def save_model(self, run_folder):\n",
    "        self.model.save(os.path.join(run_folder, 'model.h5'))\n",
    "        self.critic.save(os.path.join(run_folder, 'critic.h5'))\n",
    "        self.generator.save(os.path.join(run_folder, 'generator.h5'))\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        self.model.load_weights(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mode == 'build':\n",
    "\n",
    "    gan = WGAN(input_dim = (32,32,3)\n",
    "            , critic_conv_filters = [32,64,128,128]\n",
    "            , critic_conv_kernel_size = [5,5,5,5]\n",
    "            , critic_conv_strides = [2,2,2,1]\n",
    "            , critic_batch_norm_momentum = None\n",
    "            , critic_activation = 'leaky_relu'\n",
    "            , critic_dropout_rate = None\n",
    "            , critic_learning_rate = 0.00005\n",
    "            , generator_initial_dense_layer_size = (4, 4, 128)\n",
    "            , generator_upsample = [2,2, 2,1]\n",
    "            , generator_conv_filters = [128,64,32,3]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1,1]\n",
    "            , generator_batch_norm_momentum = 0.8\n",
    "            , generator_activation = 'leaky_relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.00005\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 670,401\n",
      "Trainable params: 670,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2D)    (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 884,163\n",
      "Trainable params: 879,619\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (-0.000)(R -0.000, F 0.000)]  [G loss: -0.000] \n",
      "1 [D loss: (-0.000)(R -0.001, F 0.000)]  [G loss: -0.001] \n",
      "2 [D loss: (-0.002)(R -0.004, F 0.000)]  [G loss: -0.002] \n",
      "3 [D loss: (-0.006)(R -0.013, F 0.001)]  [G loss: -0.007] \n",
      "4 [D loss: (-0.017)(R -0.039, F 0.006)]  [G loss: -0.026] \n",
      "5 [D loss: (-0.030)(R -0.082, F 0.022)]  [G loss: -0.072] \n",
      "6 [D loss: (-0.034)(R -0.127, F 0.059)]  [G loss: -0.131] \n",
      "7 [D loss: (-0.031)(R -0.166, F 0.104)]  [G loss: -0.186] \n",
      "8 [D loss: (-0.025)(R -0.189, F 0.139)]  [G loss: -0.217] \n",
      "9 [D loss: (-0.009)(R -0.190, F 0.171)]  [G loss: -0.222] \n",
      "10 [D loss: (-0.006)(R -0.183, F 0.170)]  [G loss: -0.215] \n",
      "11 [D loss: (-0.012)(R -0.195, F 0.171)]  [G loss: -0.204] \n",
      "12 [D loss: (-0.013)(R -0.182, F 0.156)]  [G loss: -0.186] \n",
      "13 [D loss: (-0.012)(R -0.176, F 0.151)]  [G loss: -0.168] \n",
      "14 [D loss: (-0.012)(R -0.160, F 0.136)]  [G loss: -0.152] \n",
      "15 [D loss: (-0.010)(R -0.150, F 0.131)]  [G loss: -0.138] \n",
      "16 [D loss: (-0.012)(R -0.138, F 0.115)]  [G loss: -0.124] \n",
      "17 [D loss: (-0.006)(R -0.127, F 0.116)]  [G loss: -0.113] \n",
      "18 [D loss: (-0.007)(R -0.118, F 0.104)]  [G loss: -0.094] \n",
      "19 [D loss: (-0.007)(R -0.109, F 0.095)]  [G loss: -0.074] \n",
      "20 [D loss: (-0.009)(R -0.098, F 0.080)]  [G loss: -0.053] \n",
      "21 [D loss: (0.000)(R -0.058, F 0.058)]  [G loss: -0.023] \n",
      "22 [D loss: (-0.020)(R -0.059, F 0.019)]  [G loss: 0.008] \n",
      "23 [D loss: (-0.034)(R -0.041, F -0.028)]  [G loss: 0.054] \n",
      "24 [D loss: (-0.079)(R -0.035, F -0.122)]  [G loss: 0.125] \n",
      "25 [D loss: (-0.143)(R -0.038, F -0.248)]  [G loss: 0.155] \n",
      "26 [D loss: (-0.131)(R 0.011, F -0.272)]  [G loss: 0.100] \n",
      "27 [D loss: (-0.123)(R 0.045, F -0.290)]  [G loss: 0.045] \n",
      "28 [D loss: (-0.125)(R 0.105, F -0.355)]  [G loss: 0.047] \n",
      "29 [D loss: (-0.086)(R 0.192, F -0.365)]  [G loss: 0.077] \n",
      "30 [D loss: (-0.045)(R 0.198, F -0.288)]  [G loss: 0.110] \n",
      "31 [D loss: (-0.037)(R 0.182, F -0.256)]  [G loss: 0.142] \n",
      "32 [D loss: (-0.018)(R 0.193, F -0.228)]  [G loss: 0.173] \n",
      "33 [D loss: (-0.028)(R 0.135, F -0.191)]  [G loss: 0.180] \n",
      "34 [D loss: (-0.027)(R 0.099, F -0.153)]  [G loss: 0.188] \n",
      "35 [D loss: (-0.027)(R 0.076, F -0.131)]  [G loss: 0.194] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c358e4712d04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mn_critic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN_CRITIC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;33m,\u001b[0m \u001b[0mclip_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLIP_THRESHOLD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-6-2a5d9f64b86a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, clip_threshold, using_generator)\u001b[0m\n\u001b[0;32m    300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weights-%d.h5'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2a5d9f64b86a>\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(self, run_folder)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'critic.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'generator.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \"\"\"\n\u001b[0;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1008\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    110\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 112\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    113\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    "    , clip_threshold = CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "true_imgs = (x_train[idx] + 1) *0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(true_imgs[cnt], cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, gan.z_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "#Rescale images 0 - 1\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            \n",
    "            diff = compare_images(gen_imgs[cnt, :,:,:], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i,j].imshow(c_img, cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
