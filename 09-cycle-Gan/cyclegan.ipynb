{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "from glob import glob\n",
    "\n",
    "#from models.cycleGAN import CycleGAN\n",
    "#from utils.loaders import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run params\n",
    "SECTION = 'paint'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'apple2orange'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' # 'build' # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(256, 256)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('./data/%s/%s/*' % (self.dataset_name, data_type))\n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                img = np.array(Image.fromarray(img).resize(self.img_res))\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = np.array(Image.fromarray(img).resize(self.img_res))\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('./data/%s/%sA/*' % (self.dataset_name, data_type))\n",
    "        path_B = glob('./data/%s/%sB/*' % (self.dataset_name, data_type))\n",
    "\n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "\n",
    "                img_A = np.array(Image.fromarray(img_A).resize(self.img_res))\n",
    "                img_B = np.array(Image.fromarray(img_B).resize(self.img_res))\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                    img_A = np.fliplr(img_A)\n",
    "                    img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = self.imread(path)\n",
    "        img = np.array(Image.fromarray(img).resize(self.img_res))\n",
    "        img = img/127.5 - 1.\n",
    "        return img[np.newaxis, :, :, :]\n",
    "\n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path, pilmode='RGB').astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = DataLoader(dataset_name=DATA_NAME, img_res=(IMAGE_SIZE, IMAGE_SIZE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.Generator = None  # Patch for a bug\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, LeakyReLU\n",
    "\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, add\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.Generator = None  # Patch for a bug\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, LeakyReLU\n",
    "\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, add\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class CycleGAN():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , learning_rate\n",
    "        , lambda_validation\n",
    "        , lambda_reconstr\n",
    "        , lambda_id\n",
    "        , generator_type\n",
    "        , gen_n_filters\n",
    "        , disc_n_filters\n",
    "        , buffer_max_length = 50\n",
    "        ):\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.buffer_max_length = buffer_max_length\n",
    "        self.lambda_validation = lambda_validation\n",
    "        self.lambda_reconstr = lambda_reconstr\n",
    "        self.lambda_id = lambda_id\n",
    "        self.generator_type = generator_type\n",
    "        self.gen_n_filters = gen_n_filters\n",
    "        self.disc_n_filters = disc_n_filters\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = input_dim[0]\n",
    "        self.img_cols = input_dim[1]\n",
    "        self.channels = input_dim[2]\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.buffer_A = deque(maxlen = self.buffer_max_length)\n",
    "        self.buffer_B = deque(maxlen = self.buffer_max_length)\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**3)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "        self.compile_models()\n",
    "\n",
    "        \n",
    "    def compile_models(self):\n",
    "\n",
    "        # بناء و تجميع المميز\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        \n",
    "        self.d_A.compile(loss='mse',\n",
    "            optimizer=Adam(self.learning_rate, 0.5),\n",
    "            metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "            optimizer=Adam(self.learning_rate, 0.5),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # بناء المزلد\n",
    "        if self.generator_type == 'unet':\n",
    "            self.g_AB = self.build_generator_unet()\n",
    "            self.g_BA = self.build_generator_unet()\n",
    "        else:\n",
    "            self.g_AB = self.build_generator_resnet()\n",
    "            self.g_BA = self.build_generator_resnet()\n",
    "\n",
    "        # سنقون بتدريب المولد فقط في النموذج المركب\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # الصورة المدخلة من المجالين \n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # ترجمة الصور إلى المجال الأخر \n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # ترجمة الصور إلى المجال الأصلي \n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # ربط هوية الصور \n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # تحثقق المولد من صلاحية الصور \n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # النموذج المولد سيدرب المولد على خداع المميز\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        reconstr_A, reconstr_B,\n",
    "                                        img_A_id, img_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  self.lambda_validation,                       self.lambda_validation,\n",
    "                                            self.lambda_reconstr, self.lambda_reconstr,\n",
    "                                            self.lambda_id, self.lambda_id ],\n",
    "                            optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "        self.d_A.trainable = True\n",
    "        self.d_B.trainable = True\n",
    "    \n",
    "\n",
    "    def build_generator_unet(self):\n",
    "        \n",
    "        # يتكون المولد من جزين\n",
    "        # الأول تقليل الأبعاد\n",
    "\n",
    "        def downsample(layer_input, filters, f_size=4):\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = InstanceNormalization(axis = -1, center = False, scale = False)(d)\n",
    "            d = Activation('relu')(d)\n",
    "            \n",
    "            return d\n",
    "        \n",
    "        # الثاني زيادة الأبعاد\n",
    "\n",
    "        def upsample(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(u)\n",
    "            u = InstanceNormalization(axis = -1, center = False, scale = False)(u)\n",
    "            u = Activation('relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # الصورة المدخلة\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        #Conv2D  نقوم بتقليل أبعاد الصورة باستخدام طبقات \n",
    "        # مع مقدار الخطوة= 2\n",
    "        \n",
    "        d1 = downsample(img, self.gen_n_filters) \n",
    "        d2 = downsample(d1, self.gen_n_filters*2)\n",
    "        d3 = downsample(d2, self.gen_n_filters*4)\n",
    "        d4 = downsample(d3, self.gen_n_filters*8)\n",
    "\n",
    "        # نقوم يزيادة الأبعاد\n",
    "        #تحتوي كتل زيادة الأبعاد على طبقات وصل\n",
    "        #والتي تمنح الشبكة معمارية يو نت\n",
    "        u1 = upsample(d4, d3, self.gen_n_filters*4)\n",
    "        u2 = upsample(u1, d2, self.gen_n_filters*2)\n",
    "        u3 = upsample(u2, d1, self.gen_n_filters)\n",
    "\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(img, output_img)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # Image input\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        y = img\n",
    "\n",
    "        y = conv7s1(y, self.gen_n_filters, False)\n",
    "        y = downsample(y, self.gen_n_filters * 2)\n",
    "        y = downsample(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = residual(y, self.gen_n_filters * 4)\n",
    "        y = upsample(y, self.gen_n_filters * 2)\n",
    "        y = upsample(y, self.gen_n_filters)\n",
    "        y = conv7s1(y, 3, True)\n",
    "        output = y\n",
    "\n",
    "   \n",
    "        return Model(img, output)\n",
    "\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def conv4(layer_input,filters, stride = 2, norm=True):\n",
    "            y = Conv2D(filters, kernel_size=(4,4), strides=stride, padding='same', kernel_initializer = self.weight_init)(layer_input)\n",
    "            \n",
    "            if norm:\n",
    "                y = InstanceNormalization(axis = -1, center = False, scale = False)(y)\n",
    "\n",
    "            y = LeakyReLU(0.2)(y)\n",
    "           \n",
    "            return y\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        #سلسلة من الطبقات التلافيفية ، وكلها تحتوي تسوية حالة  (باستثناء الطبقة الأولى).\n",
    "        y = conv4(img, self.disc_n_filters, stride = 2, norm = False)\n",
    "        y = conv4(y, self.disc_n_filters*2, stride = 2)\n",
    "        y = conv4(y, self.disc_n_filters*4, stride = 2)\n",
    "        y = conv4(y, self.disc_n_filters*8, stride = 1)\n",
    "        \n",
    "        # الطبقة النهائية هي طبقة تلافيفية مع مرشح واحد فقط وبدون تنشيط.\n",
    "        output = Conv2D(1, kernel_size=4, strides=1, padding='same',kernel_initializer = self.weight_init)(y)\n",
    "\n",
    "        return Model(img, output)\n",
    "\n",
    "    def train_discriminators(self, imgs_A, imgs_B, valid, fake):\n",
    "\n",
    "        # ترجمة الصور إلى المجال الأخر\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "        self.buffer_B.append(fake_B)\n",
    "        self.buffer_A.append(fake_A)\n",
    "\n",
    "        fake_A_rnd = random.sample(self.buffer_A, min(len(self.buffer_A), len(imgs_A)))\n",
    "        fake_B_rnd = random.sample(self.buffer_B, min(len(self.buffer_B), len(imgs_B)))\n",
    "\n",
    "        #لتدريب المميز  ، نستخدم أولاً المولد المعني لإنشاء مجموعة من الصور المزيفة ،\n",
    "        #ثم نقوم بتدريب كل مميز على هذه المجموعة المزيفة ومجموعة من الصور الحقيقية.\n",
    "        \n",
    "        dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "        dA_loss_fake = self.d_A.train_on_batch(fake_A_rnd, fake)\n",
    "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "        dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "        dB_loss_fake = self.d_B.train_on_batch(fake_B_rnd, fake)\n",
    "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "        # الخسارة اٌجمالية للمميز \n",
    "        d_loss_total = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "        return (\n",
    "            d_loss_total[0]\n",
    "            , dA_loss[0], dA_loss_real[0], dA_loss_fake[0]\n",
    "            , dB_loss[0], dB_loss_real[0], dB_loss_fake[0]\n",
    "            , d_loss_total[1]\n",
    "            , dA_loss[1], dA_loss_real[1], dA_loss_fake[1]\n",
    "            , dB_loss[1], dB_loss_real[1], dB_loss_fake[1]\n",
    "        )\n",
    "\n",
    "    def train_generators(self, imgs_A, imgs_B, valid):\n",
    "\n",
    "        # تجريب المميز \n",
    "        return self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                [valid, valid,\n",
    "                                                imgs_A, imgs_B,\n",
    "                                                imgs_A, imgs_B])\n",
    "\n",
    "\n",
    "    def train(self, data_loader, run_folder, epochs, test_A_file, test_B_file, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # نستخدم 1 للصور الحقيقية و 0 للصور التي تم إنشاؤها. لاحظ كيف توجد استجابة واحدة لكل رقعة\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        for epoch in range(self.epoch, epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(data_loader.load_batch()):\n",
    "\n",
    "                d_loss = self.train_discriminators(imgs_A, imgs_B, valid, fake)\n",
    "                g_loss = self.train_generators(imgs_A, imgs_B, valid)\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # طباعة التقدم \n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
    "                    % ( self.epoch, epochs,\n",
    "                        batch_i, data_loader.n_batches,\n",
    "                        d_loss[0], 100*d_loss[7],\n",
    "                        g_loss[0],\n",
    "                        np.sum(g_loss[1:3]),\n",
    "                        np.sum(g_loss[3:5]),\n",
    "                        np.sum(g_loss[5:7]),\n",
    "                        elapsed_time))\n",
    "\n",
    "                self.d_losses.append(d_loss)\n",
    "                self.g_losses.append(g_loss)\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(data_loader, batch_i, run_folder, test_A_file, test_B_file)\n",
    "                    self.combined.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (self.epoch)))\n",
    "                    self.combined.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
    "                    self.save_model(run_folder)\n",
    "\n",
    "                \n",
    "            self.epoch += 1\n",
    "\n",
    "    def sample_images(self, data_loader, batch_i, run_folder, test_A_file, test_B_file):\n",
    "        \n",
    "        r, c = 2, 4\n",
    "\n",
    "        for p in range(2):\n",
    "\n",
    "            if p == 1:\n",
    "                imgs_A = data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "                imgs_B = data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "            else:\n",
    "                imgs_A = data_loader.load_img('data/%s/testA/%s' % (data_loader.dataset_name, test_A_file))\n",
    "                imgs_B = data_loader.load_img('data/%s/testB/%s' % (data_loader.dataset_name, test_B_file))\n",
    "\n",
    "            # Translate images to the other domain\n",
    "            fake_B = self.g_AB.predict(imgs_A)\n",
    "            fake_A = self.g_BA.predict(imgs_B)\n",
    "            # Translate back to original domain\n",
    "            reconstr_A = self.g_BA.predict(fake_B)\n",
    "            reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "            # ID the images\n",
    "            id_A = self.g_BA.predict(imgs_A)\n",
    "            id_B = self.g_AB.predict(imgs_B)\n",
    "\n",
    "            gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, id_A, imgs_B, fake_A, reconstr_B, id_B])\n",
    "\n",
    "            # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "            titles = ['Original', 'Translated', 'Reconstructed', 'ID']\n",
    "            fig, axs = plt.subplots(r, c, figsize=(25,12.5))\n",
    "            cnt = 0\n",
    "            for i in range(r):\n",
    "                for j in range(c):\n",
    "                    axs[i,j].imshow(gen_imgs[cnt])\n",
    "                    axs[i, j].set_title(titles[j])\n",
    "                    axs[i,j].axis('off')\n",
    "                    cnt += 1\n",
    "            fig.savefig(os.path.join(run_folder ,\"images/%d_%d_%d.png\" % (p, self.epoch, batch_i)))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.d_A, to_file=os.path.join(run_folder ,'viz/d_A.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.d_B, to_file=os.path.join(run_folder ,'viz/d_B.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.g_BA, to_file=os.path.join(run_folder ,'viz/g_BA.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.g_AB, to_file=os.path.join(run_folder ,'viz/g_AB.png'), show_shapes = True, show_layer_names = True)\n",
    "\n",
    "\n",
    "    def save(self, folder):\n",
    "\n",
    "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
    "            pkl.dump([\n",
    "                self.input_dim\n",
    "                ,  self.learning_rate\n",
    "                ,  self.buffer_max_length\n",
    "                ,  self.lambda_validation\n",
    "                ,  self.lambda_reconstr\n",
    "                ,  self.lambda_id\n",
    "                ,  self.generator_type\n",
    "                ,  self.gen_n_filters\n",
    "                ,  self.disc_n_filters\n",
    "                ], f)\n",
    "\n",
    "        self.plot_model(folder)\n",
    "\n",
    "\n",
    "    def save_model(self, run_folder):\n",
    "\n",
    "\n",
    "        self.combined.save(os.path.join(run_folder, 'model.h5')  )\n",
    "        self.d_A.save(os.path.join(run_folder, 'd_A.h5') )\n",
    "        self.d_B.save(os.path.join(run_folder, 'd_B.h5') )\n",
    "        self.g_BA.save(os.path.join(run_folder, 'g_BA.h5')  )\n",
    "        self.g_AB.save(os.path.join(run_folder, 'g_AB.h5') )\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        self.combined.load_weights(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = CycleGAN(\n",
    "    input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "    ,learning_rate = 0.0002\n",
    "    , buffer_max_length = 50\n",
    "    , lambda_validation = 1\n",
    "    , lambda_reconstr = 10\n",
    "    , lambda_id = 2\n",
    "    , generator_type = 'unet'\n",
    "    , gen_n_filters = 32\n",
    "    , disc_n_filters = 32\n",
    "    )\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.g_BA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.g_AB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.d_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.d_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 10\n",
    "\n",
    "TEST_A_FILE = 'n07740461_14740.jpg'\n",
    "TEST_B_FILE = 'n07749192_4241.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gan.train(data_loader\n",
    "        , run_folder = RUN_FOLDER\n",
    "        , epochs=EPOCHS\n",
    "        , test_A_file = TEST_A_FILE\n",
    "        , test_B_file = TEST_B_FILE\n",
    "        , batch_size=BATCH_SIZE\n",
    "        , sample_interval=PRINT_EVERY_N_BATCHES)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot([x[1] for x in gan.g_losses], color='green', linewidth=0.1) #DISCRIM LOSS\n",
    "# plt.plot([x[2] for x in gan.g_losses], color='orange', linewidth=0.1)\n",
    "plt.plot([x[3] for x in gan.g_losses], color='blue', linewidth=0.1) #CYCLE LOSS\n",
    "# plt.plot([x[4] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.g_losses], color='red', linewidth=0.25) #ID LOSS\n",
    "# plt.plot([x[6] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[0] for x in gan.g_losses], color='black', linewidth=0.25)\n",
    "\n",
    "# plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
